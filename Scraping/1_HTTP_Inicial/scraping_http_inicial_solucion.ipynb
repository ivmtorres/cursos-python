{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping: Extrayendo datos de Internet\n",
    "\n",
    "## Introducción a HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El lenguaje principal de la internet es HTML, cuando nosotros vemos algo así\n",
    "\n",
    "![](multimedia/hello-world.jpeg)\n",
    "\n",
    "Eso se genera a partir de una código que luce así\n",
    "\n",
    "```\n",
    "<html>\n",
    "<header><title>Web Scraping - Instituto Humai</title></header>\n",
    "<body>\n",
    "<h1>¡Hola!</h1>\n",
    "<p>Esto es un sitio web</p>\n",
    "</body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "**_Nota_**: Para saber más sobre HTML podés consultar [acá](https://www.w3schools.com/TAGS/default.ASP) la lista de etiquetas de este lenguaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo consigo el código HTML?\n",
    "\n",
    "Ahora que sabemos cuál es el componente principal de los sitios webs podemos intentar programar a nuestra computadora para leer HTML y extraer información útil.\n",
    "\n",
    "Para conseguir el código de un sitio web podemos presionar ctrl+u en el navegador.\n",
    "\n",
    "Para hacer lo mismo desde python se hace lo siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos la libreria necesaria\n",
    "import requests\n",
    "\n",
    "un_sitio_web = \"https://es.wikipedia.org/wiki/HTML\"\n",
    "\n",
    "# esto descarga la información del sitio web\n",
    "# similarmente a lo que hace un navegador web antes de mostrarnos el contenido de forma mas amigable para un humano\n",
    "resultado = requests.get(un_sitio_web)\n",
    "\n",
    "# accedemos al código yendo al atributo \"text\" del resultado\n",
    "codigo_html = resultado.text\n",
    "#codigo_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué acabo de hacer?\n",
    "\n",
    "Veamos algunos detalles más sobre cómo descargar el contenido de un sitio web (O cómo se le suele decir en la jerga de la programación _realizar un request_). Como dijimos, en python se puede utilizar la función get de la libreria requests para hacer esto, veamos con mayor profundidad cómo se utiliza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.laprensa.com.ar/'\n",
    "\n",
    "headers = {'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36'}\n",
    "resp = requests.get(url, headers = headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A parte de la _url_, muchas veces se especifican los _headers_, estos son objetos que proveen datos sobre nuestro _request_, por ejemplo en el campo user-agent brindamos detalles sobre quienes somos (Nuestro sistema operativo, navegador web y demás). En este caso, como no estamos usando un navegador sino que hacemos el _request_ desde Python normalmente se omite este campo, o en caso de ser obligatorio se puede inventar, ya que algunos sitios nos van a ignorar a menos que especifiquemos este campo.\n",
    "\n",
    "- Consultas\n",
    "    - ¿Por qué los sitios te podrían bloquear/ignorar?\n",
    "    - ¿De donde saco un user-agent?\n",
    "\n",
    "Como vimos antes la función get retorna un objeto, el cual llamamos _resp_, este es un elemento de la clase _Response_ y tiene distintos atributos a los que podemos acceder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vemos el código de estado\n",
    "# 200 es que esta todo bien, 5xx o 4xx es que esta todo mal (Por ejemplo el clasico 404)\n",
    "resp.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vemos los headers que enviamos\n",
    "resp.request.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para investigar un poco mas los atributos y métodos que contiene el objeto resp pueden probar de ejecutar los comandos dir(resp) y help(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El atributo que nos interesa particularmente es resp.text, que guardan el contenido de la página.\n",
    "\n",
    "Como vamos a descargar el codigo de un sitio frecuentemente armamos una funcion para no reescribir lo mismo muchas veces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codigo_html(url):\n",
    "    headers = {'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36'}\n",
    "    resp = requests.get(url, headers = headers)\n",
    "    return resp.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentación\n",
    "La función get y la clase Response fueron desarrolladas por lxs programadores que crearon la librería requests. Si quieren saber mas sobre algún detalle siempre es recomendable buscar en la documentación oficial de la librería."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo extraigo datos útiles del código HTML?\n",
    "\n",
    "- Veamos un ejemplo inspeccionando con chrome un sitio web\n",
    "\n",
    "\n",
    "### Método 1: Expresiones regulares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RegEx para los amigos. Son un mini lenguaje de programación diseñado para realizar búsquedas en strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las funciones principales de la librería re son:\n",
    "- re.findall(pattern, string) para encontrar todos los resultados de una búsqueda\n",
    "- re.search(pattern, string) para encontrar el primer resultado que coincida\n",
    "- re.sub(pattern, replace, string) para substituir un texto por otro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursos útiles\n",
    "\n",
    "- [Testeo de regex online](https://regex101.com/)\n",
    "- [CheatSheet](https://www.dataquest.io/wp-content/uploads/2019/03/python-regular-expressions-cheat-sheet.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2><center>Sintaxis para construir regex</center></h2>\n",
    "\n",
    "\n",
    "<h3><center>Grupos de captura</center></h3>\n",
    "\n",
    "\n",
    "|     |                       |\n",
    "|-----|-----------------------|\n",
    "| ()  | grupo de captura      |\n",
    "|(?:) | grupo de no captura   |\n",
    "\n",
    "<h3><center>Tipos de datos</center></h3>\n",
    "\n",
    "\n",
    "|     |                      |          |                         |\n",
    "|----|-----------------------|----------|-------------------------|\n",
    "| \\w | caracter alfanumérico | .        | cualquier cosa menos \\n |\n",
    "| \\d | dígito                | \\|       | operador \"or\"           |\n",
    "| \\s | espacio en blanco     | [m-z3-9] | rangos                  |\n",
    "\n",
    "<h3><center>Operadores</center></h3>\n",
    "\n",
    "|         |                      |\n",
    "|---------|----------------------|\n",
    "| \\|      | operador \"or\"        |\n",
    "| []      | conjunto             |\n",
    "|[m-z3-9] | rangos               |\n",
    "\n",
    "\n",
    "<h3><center>Cuantificadores</center></h3>\n",
    "\n",
    "|      |                                              |\n",
    "|------|----------------------------------------------|\n",
    "| +    | Uno o más del elemento anterior              |\n",
    "| *    | Cero o más del elemento anterior             |\n",
    "| {4,} | Cuatro o más del elemento anterior           |\n",
    "| ?    | Cambia el operador anterior de lazy a greedy |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo se usa eso? Veamos ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1564232324']\n",
      "['1564232324']\n",
      "['1164232324']\n",
      "['11 6423-2324']\n",
      "['MES DE JUNIO']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# a- extraer números de una oración.\n",
    "\n",
    "texto = \"Mi nombre es Mathias y mi teléfono es 1564232324\"\n",
    "regla_de_busqueda = \"15\\d+\"\n",
    "print(re.findall(regla_de_busqueda,texto))\n",
    "\n",
    "# En realidad los telefonos no son cualquier seguidilla de numeros\n",
    "# suelen tener entre 6 y 8 numeros despues del 15\n",
    "texto = \"Mi nombre es María y mi teléfono es 1564232324\"\n",
    "regla_de_busqueda = \"15\\d{6,8}\"\n",
    "print(re.findall(regla_de_busqueda,texto))\n",
    "\n",
    "# En realidad los telefonos no arrancan siempre con 15\n",
    "# capaz empiezan con 11 si son de buenos aires por ejemplo\n",
    "texto = \"Mi nombre es Carlos y mi teléfono es 1164232324\"\n",
    "regla_de_busqueda = \"(?:15|11)\\d{6,8}\"\n",
    "print(re.findall(regla_de_busqueda,texto))\n",
    "\n",
    "# En realidad los telefonos pueden tener un guión o espacio a parte de números\n",
    "texto = \"Mi nombre es asfasfeaf33 y mi teléfono es 11 6423-2324\"\n",
    "regla_de_busqueda = \"(?:15|11)[0-9\\s-]{6,10}\"\n",
    "print(re.findall(regla_de_busqueda,texto))\n",
    "\n",
    "# b- Como extraer el mes de un texto\n",
    "texto = \"REPORTE DE PERFOMANCE - MES DE JUNIO\"\n",
    "regla_de_busqueda = \"(MES DE (?:JULIO|AGOSTO|JUNIO))\"\n",
    "print(re.findall(regla_de_busqueda,texto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Cómo hago que pare de buscar el operador * ?\n",
    "text = \"me llamo pedro. me gusta el rock.\"\n",
    "regla_de_busqueda_no_greedy = \"(.*?)\\.\"\n",
    "regla_de_busqueda_greedy = \"(.*)\\.\"\n",
    "print(re.findall(regla_de_busqueda_no_greedy,text))\n",
    "print(re.findall(regla_de_busqueda_greedy,text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1565525233']\n",
      "['mariadominguez']\n"
     ]
    }
   ],
   "source": [
    "# python utiliza la libreria llamada re para todo lo relacionado a regular expressions\n",
    "import re\n",
    "\n",
    "comentario_de_mercadolibre = 'hola soy @mariadominguez, me interesa el producto, te dejo mi celu 1565525233, saludos'\n",
    "\n",
    "def encontrar_telefonos(texto):\n",
    "    regla_de_busqueda = r'(15[0-9]{8})'\n",
    "    return re.findall(regla_de_busqueda, texto)\n",
    "\n",
    "def encontrar_usuarios(texto):\n",
    "    regla_de_busqueda = r'@([a-zA-Z]+)'\n",
    "    return re.findall(regla_de_busqueda, texto)\n",
    "\n",
    "print(encontrar_telefonos(comentario_de_mercadolibre))\n",
    "print(encontrar_usuarios(comentario_de_mercadolibre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usa regex para hacer una función que busque todos los emails en un texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python@hotmail.com', 'pedro_2010@yahoo.com']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encontrar_emails(texto):\n",
    "    regla_de_busqueda = r\"([a-z0-9_]+@[a-z]+\\.[a-z]+)\"\n",
    "    return re.findall(regla_de_busqueda,texto)\n",
    "\n",
    "texto = \"Hola te paso mi mail python@hotmail.com, saludos. Si no te funciona mandame a este otro, pedro_2010@yahoo.com\"\n",
    "encontrar_emails(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicandolo a la web\n",
    "##### Ejemplo 1: Usamos regex para extraer los títulos del diario La Prensa.\n",
    "\n",
    "\n",
    "```html\n",
    "<h2 class=\"entry__title\"><a href=\"http://www.laprensa.com.ar/491843-Dilemas-de-la-batalla-cultural-I.note.aspx\" target=\"_self\" onclick=\"javascript:if(typeof(_gaq)!='undefined'){_gaq.push(['_trackEvent', 'Notas', 'Cultura', 'Dilemas de la batalla cultural (I)'])};\">Dilemas de la batalla cultural (I)</a></h2>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usamos el navegador para identificar la estructura de los datos que queremos extraer y creamos el patrón de búsqueda\n",
    "regla_de_busqueda = r';\">(.+)</a></h2>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usamos findall para encontrar todas las coincidencias\n",
    "import re\n",
    "titles = [m for m in re.findall(regla_de_busqueda, codigo_html(\"http://www.laprensa.com.ar/\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Deuda: un respiro en medio de un deterioro sin precedentes',\n",
       " 'Dilemas de la batalla cultural (II)',\n",
       " 'Cupos, cupos y más cupos, el sexo del absurdo',\n",
       " 'El campo digital se expone en San Nicolás',\n",
       " 'Gracias al Bocha, el campeonato se tiñe de rojo']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modifiquen la regla de búsqueda para que descargue los links a las notas en vez del título"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método 2: BeautifulSoup\n",
    "Esta librería provee un parser de html, o sea un programa que entiende el código, permitiendonos hacer consultas mas sofisticadas de forma simple, por ejemplo \"buscame todos los titulos h2 del sitio\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rossi encabezó un acto a tres años del hundimiento del ARA San Juan\n",
      "Nuestro amo juega al esclavo\n",
      "Etiopía, el fracaso de un \n",
      "Premio Nobel de la Paz\n",
      "Sobre méritos y denarios\n",
      "El alma dividida de un gran país\n",
      "Diabetes, la otra pandemia\n",
      "Se relanza la pelea del 'streaming'\n",
      "Cuando Chicago mandó a Boca al Matadero\n",
      "Las canciones de Queen para celebrar el regreso\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(codigo_html(\"http://www.laprensa.com.ar/\"), 'html.parser')\n",
    "for title in soup.find_all(\"h2\",class_=\"entry__title\"):\n",
    "    print(title.find(\"a\").text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo 2: Cortazar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo carpeta donde voy a guardar los cuentos\n",
    "!mkdir -p multimedia/cortazar/\n",
    "\n",
    "import re\n",
    "codigo_html_crudo = codigo_html('http://ciudadseva.com/autor/julio-cortazar/cuentos/')\n",
    "\n",
    "for url_de_un_cuento in re.findall(r'(https://ciudadseva.com/texto/.+/)', codigo_html_crudo):\n",
    "    codigo_html_interpretado = BeautifulSoup(codigo_html(url_de_un_cuento), 'html.parser')\n",
    "    elem = codigo_html_interpretado.find(\"div\", { \"class\" : \"text-justify\" })\n",
    "    cuento = elem.text\n",
    "    \n",
    "    # Asi podemos guardar los resultados\n",
    "    nombre_del_archivo = url_de_un_cuento.split('/')[-2]\n",
    "    with open (f\"multimedia/cortazar/{nombre_del_archivo}.txt\", 'w') as out:\n",
    "        out.write(cuento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctica: Mercadolibre\n",
    "\n",
    "Descargá y calculá el promedio de los precios que aparecen en la primer página de mercado libre al buscar gibson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "def precios_gibson():\n",
    "    url = \"https://listado.mercadolibre.com.ar/gibson\"\n",
    "    soup = BeautifulSoup(codigo_html(url), 'html.parser')\n",
    "    prices = []\n",
    "    for price in soup.find_all(\"span\",class_=\"price-tag-fraction\"):\n",
    "        price = price.text\n",
    "        # Los precios originalmente son strings: \"101.324\"\n",
    "        # Los convierto a float (numero) de esta manera\n",
    "        price = float(price.replace(\".\",\"\"))\n",
    "        prices.append(price)\n",
    "\n",
    "    return prices\n",
    "\n",
    "precios = precios_gibson()\n",
    "import numpy as np\n",
    "print(f\"El precio promedio es {int(np.nanmean(precios))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Entonces me puedo descargar todo internet?\n",
    "\n",
    "En la próximas clases veremos algunas limitaciones de este método y sus alternativas. Mas allá de eso es importante ponerse de vez en cuando en el lugar del sitio del cual estamos descargando datos.\n",
    "\n",
    "\n",
    "Muchas veces las páginas web obtienen sus ingresos a partir del uso de usuarios tradicionales (humanos) pero no de los scrapers (máquinas). Por lo que estos no generan ganancias al sitio y encima pueden causar congestión en los servidores (Pudiendo causar incluso la rotura del sitio similar a lo que pasa con los [ataques DDOS](https://es.wikipedia.org/wiki/Ataque_de_denegaci%C3%B3n_de_servicio)).\n",
    "\n",
    "Por esta razón los sitios webs suelen tener una pagina [/robots.txt](https://es.wikipedia.org/wiki/Est%C3%A1ndar_de_exclusi%C3%B3n_de_robots) donde especifican que tipo de scrapeo prefieren evitar para poder mantener su sitio funcionando correctamente sin problemas.\n",
    "\n",
    "Pueden ver, como ejemplos:\n",
    "\n",
    "- https://www.google.com/robots.txt\n",
    "- https://en.wikipedia.org/robots.txt"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
